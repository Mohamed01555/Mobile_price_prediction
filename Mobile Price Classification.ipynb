{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Price Classification\n",
    "\n",
    "use the given train and test [data](https://www.kaggle.com/iabhishekofficial/mobile-price-classification#train.csv) to train a logistic regression model to predict the price range of the phone\n",
    "\n",
    "![mobile range classification](../res/phone.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../datasets/train_mobile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0               842     0          2.2         0   1       0           7   \n",
       "1              1021     1          0.5         1   0       1          53   \n",
       "2               563     1          0.5         1   2       1          41   \n",
       "3               615     1          2.5         0   0       0          10   \n",
       "4              1821     1          1.2         0  13       1          44   \n",
       "...             ...   ...          ...       ...  ..     ...         ...   \n",
       "1995            794     1          0.5         1   0       1           2   \n",
       "1996           1965     1          2.6         1   0       0          39   \n",
       "1997           1911     0          0.9         1   1       1          36   \n",
       "1998           1512     0          0.9         0   4       1          46   \n",
       "1999            510     1          2.0         1   5       1          45   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0       0.6        188        2  ...         20       756  2549     9     7   \n",
       "1       0.7        136        3  ...        905      1988  2631    17     3   \n",
       "2       0.9        145        5  ...       1263      1716  2603    11     2   \n",
       "3       0.8        131        6  ...       1216      1786  2769    16     8   \n",
       "4       0.6        141        2  ...       1208      1212  1411     8     2   \n",
       "...     ...        ...      ...  ...        ...       ...   ...   ...   ...   \n",
       "1995    0.8        106        6  ...       1222      1890   668    13     4   \n",
       "1996    0.2        187        4  ...        915      1965  2032    11    10   \n",
       "1997    0.7        108        8  ...        868      1632  3057     9     1   \n",
       "1998    0.1        145        5  ...        336       670   869    18    10   \n",
       "1999    0.9        168        6  ...        483       754  3919    19     4   \n",
       "\n",
       "      talk_time  three_g  touch_screen  wifi  price_range  \n",
       "0            19        0             0     1            1  \n",
       "1             7        1             1     0            2  \n",
       "2             9        1             1     0            2  \n",
       "3            11        1             0     0            2  \n",
       "4            15        1             1     0            1  \n",
       "...         ...      ...           ...   ...          ...  \n",
       "1995         19        1             1     0            0  \n",
       "1996         16        1             1     1            2  \n",
       "1997          5        1             1     0            3  \n",
       "1998         19        1             1     1            0  \n",
       "1999          2        1             1     1            3  \n",
       "\n",
       "[2000 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb82821a350>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['price_range'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[: , :-1].values\n",
    "Y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test = train_test_split(X , Y , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=4, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=4)\n",
    "pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999015656691174"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If I want to use PCA I shouldn't scale data because by scaling I remove correlaton between data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.44714363, -0.99501244, -0.7478303 , ..., -1.7644009 ,\n",
       "         1.        , -1.04475034],\n",
       "       [ 1.42577572,  1.00501256,  1.20170694, ...,  0.56676462,\n",
       "        -1.        , -1.04475034],\n",
       "       [-0.53571906,  1.00501256,  1.68909125, ...,  0.56676462,\n",
       "        -1.        , -1.04475034],\n",
       "       ...,\n",
       "       [-0.39252766, -0.99501244, -1.11336854, ...,  0.56676462,\n",
       "         1.        , -1.04475034],\n",
       "       [ 0.99847443,  1.00501256,  0.95801479, ...,  0.56676462,\n",
       "        -1.        , -1.04475034],\n",
       "       [ 1.68942971,  1.00501256,  0.10509224, ...,  0.56676462,\n",
       "         1.        ,  0.95716648]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# x_train = sc.fit_transform(x_train)\n",
    "# x_test = sc.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_pca = PCA(n_components=5)\n",
    "# new_pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37223481389435215"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.sum(new_pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67011561, 0.16648706, 0.10887934, 0.05352925])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pca.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is SGDClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74       110\n",
      "           1       0.50      0.12      0.19        93\n",
      "           2       0.37      0.57      0.45       102\n",
      "           3       0.09      0.03      0.05        95\n",
      "\n",
      "    accuracy                           0.46       400\n",
      "   macro avg       0.39      0.43      0.36       400\n",
      "weighted avg       0.39      0.46      0.37       400\n",
      "\n",
      "this is LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       110\n",
      "           1       0.96      0.95      0.95        93\n",
      "           2       0.96      0.92      0.94       102\n",
      "           3       0.95      0.98      0.96        95\n",
      "\n",
      "    accuracy                           0.96       400\n",
      "   macro avg       0.96      0.96      0.96       400\n",
      "weighted avg       0.96      0.96      0.96       400\n",
      "\n",
      "this is RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedalgebali/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       110\n",
      "           1       0.88      0.85      0.86        93\n",
      "           2       0.85      0.86      0.86       102\n",
      "           3       0.91      0.89      0.90        95\n",
      "\n",
      "    accuracy                           0.89       400\n",
      "   macro avg       0.89      0.89      0.89       400\n",
      "weighted avg       0.89      0.89      0.89       400\n",
      "\n",
      "this is KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       110\n",
      "           1       0.93      0.90      0.92        93\n",
      "           2       0.89      0.89      0.89       102\n",
      "           3       0.94      0.93      0.93        95\n",
      "\n",
      "    accuracy                           0.93       400\n",
      "   macro avg       0.93      0.93      0.93       400\n",
      "weighted avg       0.93      0.93      0.93       400\n",
      "\n",
      "this is XGBClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       110\n",
      "           1       0.89      0.88      0.89        93\n",
      "           2       0.89      0.88      0.89       102\n",
      "           3       0.92      0.93      0.92        95\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier , LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "clfs = [SGDClassifier(), LogisticRegression(), RandomForestClassifier(), KNeighborsClassifier(n_neighbors=7),\n",
    "       XGBClassifier()]\n",
    "for clf in clfs:\n",
    "    print(f'this is {clf.__class__.__name__}')\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(classification_report(y_test , y_pred))\n",
    "    pd.DataFrame(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedalgebali/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's obvoius that Logistic regression is the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(test_input):\n",
    "    '''Accept a numpy array contains mobile spacification'''\n",
    "    test_input = test_input.reshape(1,-1)\n",
    "    test_input = pca.transform(test_input)\n",
    "    y_pred = lr.predict(test_input)\n",
    "    y_pred_proba = lr.predict_proba(test_input)\n",
    "    return f'this mobile of class {y_pred} with probability {y_pred_proba}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.53508605e-09 9.99023715e-01 9.76282877e-04 3.20660245e-18]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'this mobile of class [1] with probability [[2.53508605e-09 9.99023715e-01 9.76282877e-04 3.20660245e-18]]'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test(np.array(dataset.iloc[0,:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
